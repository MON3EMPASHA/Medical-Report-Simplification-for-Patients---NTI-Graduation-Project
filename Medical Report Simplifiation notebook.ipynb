{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "df = pd.read_csv(\"hf://datasets/vishnukantshukla/medical-complex-to-simple-10k/medical_simplified.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The lungs are clear of focal consolidation, pleural effusion or pneumothorax. The heart size is normal. The mediastinal contours are normal. Multiple surgical clips project over the left breast, and old left rib fractures are noted.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Standard_English'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "480232102005467ebf896a90ab653d6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8985 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AIJimmy\\miniconda3\\envs\\torch\\lib\\site-packages\\transformers\\tokenization_utils_base.py:4007: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# if your data is a pandas dataframe\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    model_inputs = tokenizer(\n",
    "        examples[\"Standard_English\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True\n",
    "    )\n",
    "    # Tokenize labels\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            examples[\"Simplified_English\"],\n",
    "            padding=\"max_length\",\n",
    "            truncation=True\n",
    "        )\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Standard_English</th>\n",
       "      <th>Simplified_English</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The lungs are clear of focal consolidation, pl...</td>\n",
       "      <td>The lungs look healthy, with no signs of infec...</td>\n",
       "      <td>[37, 3, 17454, 33, 964, 13, 15949, 16690, 6, 3...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[37, 3, 17454, 320, 1695, 6, 28, 150, 3957, 13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lung volumes remain low. There are innumerable...</td>\n",
       "      <td>The lungs don't have their full capacity. Ther...</td>\n",
       "      <td>[301, 425, 13548, 2367, 731, 5, 290, 33, 16, 5...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[37, 3, 17454, 278, 31, 17, 43, 70, 423, 2614,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lung volumes are low. This results in crowding...</td>\n",
       "      <td>The lungs don't have their full capacity, whic...</td>\n",
       "      <td>[301, 425, 13548, 33, 731, 5, 100, 772, 16, 43...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[37, 3, 17454, 278, 31, 17, 43, 70, 423, 2614,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>There is mild pulmonary edema with small bilat...</td>\n",
       "      <td>There is some fluid buildup in the lungs. The ...</td>\n",
       "      <td>[290, 19, 8248, 3, 26836, 3, 15, 1778, 9, 28, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[290, 19, 128, 5798, 918, 413, 16, 8, 3, 17454...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The right costophrenic angle is not imaged. Ot...</td>\n",
       "      <td>The right side of the chest is not fully visib...</td>\n",
       "      <td>[37, 269, 583, 10775, 60, 2532, 7669, 19, 59, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[37, 269, 596, 13, 8, 5738, 19, 59, 1540, 5183...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Standard_English  \\\n",
       "0  The lungs are clear of focal consolidation, pl...   \n",
       "1  Lung volumes remain low. There are innumerable...   \n",
       "2  Lung volumes are low. This results in crowding...   \n",
       "3  There is mild pulmonary edema with small bilat...   \n",
       "4  The right costophrenic angle is not imaged. Ot...   \n",
       "\n",
       "                                  Simplified_English  \\\n",
       "0  The lungs look healthy, with no signs of infec...   \n",
       "1  The lungs don't have their full capacity. Ther...   \n",
       "2  The lungs don't have their full capacity, whic...   \n",
       "3  There is some fluid buildup in the lungs. The ...   \n",
       "4  The right side of the chest is not fully visib...   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [37, 3, 17454, 33, 964, 13, 15949, 16690, 6, 3...   \n",
       "1  [301, 425, 13548, 2367, 731, 5, 290, 33, 16, 5...   \n",
       "2  [301, 425, 13548, 33, 731, 5, 100, 772, 16, 43...   \n",
       "3  [290, 19, 8248, 3, 26836, 3, 15, 1778, 9, 28, ...   \n",
       "4  [37, 269, 583, 10775, 60, 2532, 7669, 19, 59, ...   \n",
       "\n",
       "                                      attention_mask  \\\n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                              labels  \n",
       "0  [37, 3, 17454, 320, 1695, 6, 28, 150, 3957, 13...  \n",
       "1  [37, 3, 17454, 278, 31, 17, 43, 70, 423, 2614,...  \n",
       "2  [37, 3, 17454, 278, 31, 17, 43, 70, 423, 2614,...  \n",
       "3  [290, 19, 128, 5798, 918, 413, 16, 8, 3, 17454...  \n",
       "4  [37, 269, 596, 13, 8, 5738, 19, 59, 1540, 5183...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tokenized_datasets).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 7188\n",
      "Evaluation dataset size: 1797\n"
     ]
    }
   ],
   "source": [
    "train_test_split = tokenized_datasets.train_test_split(test_size=0.2)\n",
    "\n",
    "train_dataset = train_test_split[\"train\"]\n",
    "eval_dataset = train_test_split[\"test\"]\n",
    "\n",
    "print(\"Training dataset size:\", len(train_dataset))\n",
    "print(\"Evaluation dataset size:\", len(eval_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "from transformers import AutoModelForSeq2SeqLM, BitsAndBytesConfig,AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model_name = \"google/flan-t5-base\"\n",
    "\n",
    "# Load tokenizer and fix pad token\n",
    "\n",
    "\n",
    "# Configure 4-bit quantization\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,  # or torch.bfloat16\n",
    "    bnb_4bit_use_double_quant=True,       # Optional: for better compression\n",
    "    bnb_4bit_quant_type=\"nf4\"             # Optional: normalized float 4-bit\n",
    ")\n",
    "\n",
    "# Load model with quantization config\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=\"auto\",  # Optional: for automatic device placement\n",
    "    torch_dtype=torch.float16  # Optional: for consistency\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,769,472 || all params: 249,347,328 || trainable%: 0.7096\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "from transformers import  DataCollatorForSeq2Seq\n",
    "# LoRA configuration\n",
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q\", \"v\", \"k\", \"o\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_2_SEQ_LM\")\n",
    "model = get_peft_model(base_model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_train_batch_size=2,      # Reduced for memory safety\n",
    "    per_device_eval_batch_size=2,       # Reduced for memory safety\n",
    "    gradient_accumulation_steps=8,      # Increased to maintain effective batch size\n",
    "    num_train_epochs=2,                 # Slightly more epochs since batch size is smaller\n",
    "    logging_steps=50,                   # More frequent logging for shorter runs\n",
    "    save_steps=250,                     # More frequent saves for Colab\n",
    "    learning_rate=3e-4,                 # Slightly higher LR for smaller batches\n",
    "    fp16=False,                          # Changed from bf16 (better Colab compatibility)\n",
    "    optim=\"adamw_torch\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=data_collator,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='900' max='900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [900/900 36:44, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.805300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>4.300300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>4.139300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.987300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.885000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.783000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>3.664300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.596700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>3.548300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.424600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>3.218900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.772700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.202900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.662700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>1.421100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.324100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>1.327600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.299100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=900, training_loss=3.0201713053385415, metrics={'train_runtime': 2207.2638, 'train_samples_per_second': 6.513, 'train_steps_per_second': 0.408, 'total_flos': 1.0363940647206912e+16, 'train_loss': 3.0201713053385415, 'epoch': 2.0})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='899' max='899' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [899/899 02:22]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7353515625, 'eval_runtime': 142.6279, 'eval_samples_per_second': 12.599, 'eval_steps_per_second': 6.303, 'epoch': 2.0}\n"
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"lora_flan_t5_base_medical_simplification.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model.state_dict(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./medical_lora_adapters\\\\tokenizer_config.json',\n",
       " './medical_lora_adapters\\\\special_tokens_map.json',\n",
       " './medical_lora_adapters\\\\spiece.model',\n",
       " './medical_lora_adapters\\\\added_tokens.json',\n",
       " './medical_lora_adapters\\\\tokenizer.json')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model = trainer.model\n",
    "\n",
    "peft_model.save_pretrained(\"./medical_lora_adapters\")\n",
    "tokenizer.save_pretrained(\"./medical_lora_adapters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simplified: The horn of the medial meniscus is a complex tear in the lower part of the horn. The lungs are displaced.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Load your fine-tuned model\n",
    "model_name = \"./medical_lora_adapters\" # path or HF repo\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(\"cuda\")\n",
    "\n",
    "# Input sentence\n",
    "sentence = \"Complex tear of the posterior horn of the medial meniscus with a displaced bucket-handle component.\"\n",
    "# Encode & generate\n",
    "inputs = tokenizer(sentence, return_tensors=\"pt\").to(\"cuda\")\n",
    "outputs = model.generate(**inputs, max_new_tokens=100)\n",
    "\n",
    "# Decode\n",
    "simplified = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(\"Simplified:\", simplified)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
